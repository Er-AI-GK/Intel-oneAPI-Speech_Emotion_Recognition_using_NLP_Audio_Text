{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bf74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Based Emotion Recog using NLP Vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f736b59-d100-4246-a53c-bc9ea45f485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: onednn-cpu-gomp in /home/u190492/.local/lib/python3.9/site-packages (2023.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install onednn-cpu-gomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5123fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/u190492/.local/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: packaging in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (2.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (0.4.8)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (1.53.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (4.22.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/u190492/.local/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.7 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.7.3)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /home/u190492/.local/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/u190492/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/u190492/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/u190492/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/u190492/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/u190492/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/u190492/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/u190492/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/u190492/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/u190492/.local/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/u190492/.local/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.12.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/u190492/.local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/u190492/.local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35e3e501-e7eb-424d-8253-3a6e0772080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b477834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0203969e-0308-4bce-a997-9a08430687aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/u190492/.local/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/u190492/.local/lib/python3.9/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/u190492/.local/lib/python3.9/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: joblib in /glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from nltk) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "#install the NLTK (Natural Language Toolkit)\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e0b6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "train=pd.read_table('train.txt', delimiter = ';', header=None, )\n",
    "val=pd.read_table('val.txt', delimiter = ';', header=None, )\n",
    "test=pd.read_table('test.txt', delimiter = ';', header=None, )\n",
    "\n",
    "data = pd.concat([train ,  val , test])\n",
    "data.columns = [\"text\", \"label\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44756fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3042a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eac3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text preprocessing\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess(line):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', line) #leave only characters from a to z\n",
    "    review = review.lower() #lower the text\n",
    "    review = review.split() #turn string into list of words\n",
    "    #apply Stemming \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')] #delete stop words like I, and ,OR   review = ' '.join(review)\n",
    "    #trun list into sentences\n",
    "    return \" \".join(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d230e70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/u190492/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#install the NLTK (Natural Language Toolkit)\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b585db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['text'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32480b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data['N_label'] = label_encoder.fit_transform(data['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c8fea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       didnt feel humili\n",
       "1       go feel hopeless damn hope around someon care ...\n",
       "2                    im grab minut post feel greedi wrong\n",
       "3          ever feel nostalg fireplac know still properti\n",
       "4                                            feel grouchi\n",
       "                              ...                        \n",
       "1995    keep feel like someon unkind wrong think get b...\n",
       "1996              im feel littl cranki neg doctor appoint\n",
       "1997                feel use peopl give great feel achiev\n",
       "1998    im feel comfort derbi feel though start step s...\n",
       "1999    feel weird meet w peopl text like dont talk fa...\n",
       "Name: text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "596e2847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model by applying Countvectorizer -convert textual data to numerical data\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=5000,ngram_range=(1,3))#example: the course was long-> [the,the course,the course was,course, course was, course was long,...]\n",
    "\n",
    "data_cv = cv.fit_transform(data['text']).toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "273c3e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d54b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test=data_cv,test_cv,train['N_label'],test['N_label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(data_cv, data['N_label'], test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33985ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.0831 - accuracy: 0.5949\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3234 - accuracy: 0.8983\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1604 - accuracy: 0.9486\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1020 - accuracy: 0.9681\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0683 - accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0494 - accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0375 - accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0294 - accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0226 - accuracy: 0.9929\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0187 - accuracy: 0.9948\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.9959\n",
      "Accuracy: 99.59\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the dataset\n",
    "# split into input (X) and output (y) variables\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# compile the keras model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6867f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.7810 - accuracy: 0.8532\n",
      "Accuracy: 85.32\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fee946e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='Hello World !'\n",
    "text=preprocess(text)\n",
    "array = cv.transform([text]).toarray()\n",
    "pred = model.predict(array)\n",
    "a=np.argmax(pred, axis=1)\n",
    "label_encoder.inverse_transform(a)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "411dcb56-410f-45e6-92f6-d976d8e68ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5877746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'my_modelnew.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea79609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(label_encoder, open('encoder.pkl', 'wb'))\n",
    "pickle.dump(cv, open('CountVectorizer.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f873e80-bffe-4432-b3fa-cb1f3e7c96e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IntelÂ® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
